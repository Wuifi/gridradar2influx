{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridradar API\n",
    "https://gridradar.net/de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "import requests\n",
    "import json\n",
    "import pprint\n",
    "from lib.gridradar_api import *\n",
    "from lib.basic_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "\n",
    "#Gridradar.net API configuration\n",
    "APItoken = config.APItoken\n",
    "#InfluxDB configuration\n",
    "influx_host =  config.influx_host\n",
    "influx_port = config.influx_port # os.environ.get('INFLUX_PORT')\n",
    "influx_username = config.influx_username\n",
    "influx_password = config.influx_password\n",
    "influx_database = config.influx_database\n",
    "location = config.location \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://api.gridradar.net/aggr_functions?token=4W01v742EaQ9iZj11B55vjaA4RyOtsNmu6M26EH09mFxlswbOSxA2X9bxuwZOBnpaYXtXyXf+xeQYl2LnQxev35WbGQVruURZteEpe52C0FVv08wXcb9Xm5f6Dvn/L3a\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Metrics\n",
    "**KEY**                            DESCRIPTION\\\n",
    "**- frequency**\\\n",
    "PMU selection, frequency 100ms, max period per query 1h\\\n",
    "**- frequency-mean-1m**\\\n",
    "PMU selection, 1m avg., max period per query 30d\\\n",
    "**- frequency-mean-1s**\\\n",
    "PMU selection, 1s avg., max period per query 12h\\\n",
    "**- frequency-ucte-median-1s**\\\n",
    "Median of the pmu 1 second mean frequencies\\\n",
    "**- net-time**\\\n",
    "Network time deviation of the UCTE power grid\\\n",
    "**- phase-angle**\\\n",
    "PMU selection, phase angle 100ms, max period per query 1h\\\n",
    "**- phase-angle-first-1m**\\\n",
    "PMU selection, first val. of minute, max period per query 30d\\\n",
    "**- phase-angle-first-1s**\\\n",
    "PMU selection, first val. of second, max period per query 12h\\\n",
    "\n",
    "\n",
    "columns\t\n",
    "0\t\"function\"\n",
    "1\t\"description\"\n",
    "data\t\n",
    "0\t\n",
    "0\t\"count\"\n",
    "1\t\"number of non-null values\"\n",
    "1\t\n",
    "0\t\"mean\"\n",
    "1\t\"arithmetic average of values\"\n",
    "2\t\n",
    "0\t\"median\"\n",
    "1\t\"middle value of the sorted list of values.\"\n",
    "3\t\n",
    "0\t\"spread\"\n",
    "1\t\"difference between the minimum and maximum values\"\n",
    "4\t\n",
    "0\t\"stddev\"\n",
    "1\t\"the standard deviation of values.\"\n",
    "5\t\n",
    "0\t\"sum\"\n",
    "1\t\"sum of values\"\n",
    "6\t\n",
    "0\t\"difference\"\n",
    "1\t\"difference between subsequent values\"\n",
    "7\t\n",
    "0\t\"min\"\n",
    "1\t\"lowest value\"\n",
    "8\t\n",
    "0\t\"max\"\n",
    "1\t\"greatest value\"\n",
    "9\t\n",
    "0\t\"first\"\n",
    "1\t\"the value with the oldest timestamp\"\n",
    "10\t\n",
    "0\t\"last\"\n",
    "1\t\"the value with the newest timestamp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two different loops:\n",
    "# query high_resolution data with short timerange every 30min\n",
    "# query low_resolution data every 6hrs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get data from influxDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from influxdb import DataFrameClient\n",
    "\n",
    "clientDF = DataFrameClient(influx_host,\n",
    "                           influx_port,\n",
    "                           influx_username,\n",
    "                           influx_password,\n",
    "                           influx_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clientDF.query('SELECT \"value\" FROM \"gridradar\".\"autogen\".\"frequency\"')\n",
    "metric='frequency'\n",
    "influxquerystr=(r'SELECT last(\"value\"), time FROM \"gridradar\".\"autogen\".\"'+ metric +r'\"')\n",
    "response = clientDF.query(influxquerystr)\n",
    "\n",
    "if len(response) == 0:\n",
    "    print(\"Dict is Empty\")\n",
    "print(response)\n",
    "print(type(response))\n",
    "print(response[metric])\n",
    "print(type(response[metric]))\n",
    "#['list']\n",
    "#SELECT last(<field name>), time FROM network WHERE device_id = 'x'\n",
    "#SELECT last(<field name>), time FROM usage WHERE device_id = 'x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_last_influx_datapoint = response[metric].index.time#.to_datetime\n",
    "print(timestamp_last_influx_datapoint)\n",
    "print(type(timestamp_last_influx_datapoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(type(timestamp_last_influx_datapoint))#.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "#timestamp_last_influx_datapoint = datetime.datetime(timestamp_last_influx_datapoint)\n",
    "#timestamp_last_influx_datapoint.astype(\"datetime64[ns]\")\n",
    "print(timestamp_last_influx_datapoint)\n",
    "print(type(timestamp_last_influx_datapoint))\n",
    "\n",
    "now = datetime.utcnow()\n",
    "print(now)\n",
    "print(type(now))\n",
    "# get timestamp of last datapoint in influxd for each query\n",
    "#timestamp_last_influx_datapoint = now #- timedelta(hours=settings['timerange'])\n",
    "# compare with timerange for query and adjust if overlap\n",
    "\n",
    "starttime = (now - timedelta(hours=settings['timerange']))\n",
    "if (timestamp_last_influx_datapoint < starttime):\n",
    "    print('wert in influxDB kleiner als timerange')\n",
    "    starttime = timestamp_last_influx_datapoint\n",
    "print(starttime)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get data from API with dynamic time ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Request and header parameters\n",
    "url = 'https://api.gridradar.net/query'\n",
    "token = config.APItoken#'<token>'\n",
    "\n",
    "headers = {\n",
    "    'Content-type': 'application/json', \n",
    "    'Authorization': 'Bearer '+token\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dataset_test(metric,response_dict,location):\n",
    "    outDB=[]\n",
    "    logging.info(\"gridradar-API - response: %s\", response_dict)\n",
    "    messdaten=response_dict[0]\n",
    "        \n",
    "    for values in messdaten['datapoints']:\n",
    "        #print(type(values[0]))\n",
    "        try:\n",
    "            if math.isnan(values[0])==False:\n",
    "                outDB_new = {'measurement': metric,\n",
    "                             'tags': {'location': location},\n",
    "                             'fields': {'value': values[0]},\n",
    "                             #'fields': {messdaten['target']: values[0]},\n",
    "                             'time':timestamp_convert(values[1])}\n",
    "                outDB.append(outDB_new)\n",
    "        except Exception as e:\n",
    "            logging.error(str(e),str(values))\n",
    "    return(outDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#InfluxDB configuration\n",
    "import influxdb\n",
    "\n",
    "influxdb_client = influxdb.InfluxDBClient(\n",
    "            influx_host,\n",
    "            influx_port,\n",
    "            influx_username,\n",
    "            influx_password,\n",
    "            influx_database, \n",
    "            ssl = False,\n",
    "            verify_ssl = True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict of available metrics\n",
    "metrics_dict={\n",
    "    #\"frequency\":{\"aggr\":\"100ms\", \"timerange\":1, 'metric_id':1},        #'\"1h\"'\n",
    "    #\"frequency-mean-1m\":{\"aggr\":\"1m\", \"timerange\":720, 'metric_id':2}, #'\"30d\"'\n",
    "    #\"frequency-mean-1s\":{\"aggr\":\"1s\", \"timerange\":12, 'metric_id':3},  #'\"12h\"'\n",
    "    #\"frequency-ucte-median-1s\":{\"aggr\":\"1s\", \"timerange\":24, 'metric_id':4}, #'\"1d\"'\n",
    "    #\"net-time\":{\"aggr\":\"1s\", \"timerange\":24, 'metric_id':5},           #'\"1d\"'\n",
    "    \"phase-angle\":{\"aggr\":\"100ms\", \"timerange\":1, 'metric_id':6},      #'\"1h\"'\n",
    "    \"phase-angle-first-1m\":{\"aggr\":\"1m\", \"timerange\":720, 'metric_id':7}, #'\"30d\"'\n",
    "    \"phase-angle-first-1m\":{\"aggr\":\"1s\", \"timerange\":12, 'metric_id':8} #'\"12h\"'\n",
    "}\n",
    "#metric = \"frequency\"\n",
    "#settings = metrics_dict[metric]\n",
    "#aggr = settings['aggr']\n",
    "#timerange = settings['timerange']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics_dict={\n",
    "#    \"frequency\":{\"aggr\":\"100ms\", \"timerange\":1, 'metric_id':1}        #'\"1h\"'\n",
    "#    #\"frequency-mean-1m\":{\"aggr\":\"1m\", \"timerange\":720, 'metric_id':2}\n",
    "#    }\n",
    "for metric, settings in metrics_dict.items():\n",
    "    \n",
    "    ## define API query parameters\n",
    "    response = getdatafromapi(url,token,metric_request_creator(metric,metrics_dict,location))\n",
    "    ## Converting the JSON response string to a Python dictionary\n",
    "    response_dict = json.loads(response.content)\n",
    "    ## Pretty print response dictionary\n",
    "    #pprint.pprint(response_dict)\n",
    "    out_influxDB = convert_dataset_test(metric,response_dict,location)\n",
    "    #pprint.pprint(out_influxDB)\n",
    "    influxdb_client.write_points(out_influxDB,database= influx_database,\n",
    "                                    time_precision=\"ms\",\n",
    "                                    batch_size=10000,\n",
    "                                    protocol='json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write data to influxdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "def convert_dataset_old(response,metric,location,ctr,uptime):\n",
    "    pprint.pprint(response.status_code)\n",
    "    logging.debug(\"API response status code: {}\".format(response.status_code))\n",
    "    #pprint.pprint(response.content)\n",
    "    ## Converting the JSON response string to a Python dictionary\n",
    "    result_dict = json.loads(response.content)\n",
    "    #pprint.pprint(result_dict)\n",
    "    messdaten=result_dict[0]\n",
    "\n",
    "    outDB=[]\n",
    "    for values in messdaten['datapoints']:\n",
    "        #print(type(values[0]))\n",
    "        if math.isnan(values[0])==False:\n",
    "            outDB_new = {\n",
    "                'measurement': metric,\n",
    "                'tags': {'location': location},\n",
    "                'fields': {'value': values[0]},\n",
    "                'time':timestamp_convert(values[1])\n",
    "                }\n",
    "            outDB.append(outDB_new)\n",
    "    # add response state and time to data output for debugging purposes\n",
    "    #if metric=='median_frequency':\n",
    "    #    request_type=1\n",
    "    #elif metric=='net_time':\n",
    "    #    request_type=2\n",
    "    #else:\n",
    "    #    request_type=0\n",
    "    #metric_id\n",
    "    \n",
    "    debug_info = {\n",
    "        'measurement': 'API_stats',\n",
    "        'tags': {'location': location, 'metric':metric},\n",
    "        'fields': {\n",
    "            'request_counter': ctr,\n",
    "            #'request_type':request_type,\n",
    "            'stat_code':response.status_code,\n",
    "            'uptime':int(uptime)},\n",
    "            'time':time_now()}\n",
    "    outDB.append(debug_info)\n",
    "    #print(type(outDB))\n",
    "    #outDB\n",
    "    return(outDB)\n",
    "\n",
    "def data_wrangler(url,request,metric,location,headers,ctr,uptime):\n",
    "    try:\n",
    "        ctr=ctr+1\n",
    "        ## Converting the Python dictionary to a JSON string\n",
    "        json_request = json.dumps(request)\n",
    "        ## Request execution and response reception\n",
    "        response = requests.post(url, data=json_request, headers=headers)\n",
    "\n",
    "        out_influxDB=convert_dataset(response,metric,location,ctr,uptime)\n",
    "        #pprint.pprint(out_influxDB)\n",
    "        #logging.debug(\"Read initial value: {:.2f}\".format(m3abs))\n",
    "        \n",
    "        client.write_points(out_influxDB, database='gridradar', time_precision='ms', batch_size=10000, protocol='json') \n",
    "        #print('gridradar2influx.py  --  request counter: ',str(ctr),'for ',measurement,' written to InfluxDB')\n",
    "        logging.info('gridradar2influx.py  --  request counter: {} for {} written to InfluxDB'.format(ctr,metric))\n",
    "        #logging.info(\"Read initial value: {:.2f}\".format(m3abs))\n",
    "    except (ValueError, TypeError) as ex:\n",
    "        #debug_str='\"%s\" cannot be converted to an float: %s' % (raw_content, ex)\n",
    "        print(ex)\n",
    "        \n",
    "    return ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uptime=0\n",
    "ctr=0\n",
    "print(metric)\n",
    "out_influxDB=convert_dataset(response,metric,querypmu,ctr,uptime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "influxdb_client.write_points(out_influxDB,database= influx_database,\n",
    "                                    time_precision=\"ms\",\n",
    "                                    batch_size=10000,\n",
    "                                    protocol='json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffreq=clientDF.query('SELECT \"value\" FROM \"gridradar\".\"autogen\".\"frequency\"')\n",
    "dffreq=dffreq['frequency']#[0]\n",
    "dffreq=dffreq.rename(columns={'value': 'frequency'})\n",
    "dffreq['datetime']=dffreq.index\n",
    "dffreq=dffreq[dffreq[\"datetime\"]>'2023-04-01']\n",
    "dffreq.head(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftime=clientDF.query('SELECT \"value\" FROM \"gridradar\".\"autogen\".\"net_time\"')\n",
    "dftime=dftime['net_time']\n",
    "dftime=dftime.rename(columns={'value': 'net_time'})\n",
    "\n",
    "dftime['datetime']=dftime.index\n",
    "print(dftime[\"datetime\"].max() - dftime[\"datetime\"].min())\n",
    "dftime.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "dfplottime=dftime[dftime[\"datetime\"]>'2022-02-02']\n",
    "fig = px.line(dfplottime,x=\"datetime\",y=\"net_time\", title='gridradar net_time data from influxDB')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
